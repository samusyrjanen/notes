{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kubeflow Pipelines (KFP)\n",
    "To learn how to use Kubeflow Pipelines, it is important to understand the following concepts:\n",
    "\n",
    "*KFP pipeline*: A KFP pipeline is a directed acyclic graph of ML tasks. A KFP pipeline can consist of multiple tasks, such as data preprocessing, model training, evaluation, and deployment. The pipeline defines the dependencies between these tasks and the order in which they should be executed.\n",
    "\n",
    "*KFP component*: A KFP component performs a specific task of a KFP pipeline. In other words, a KFP pipeline consist of one or more KFP components.\n",
    "\n",
    "*KFP run*: A KFP run is a single execution of a KFP pipeline.\n",
    "\n",
    "*KFP experiment*: A KFP experiment has one or more KFP runs. It can be seen as a workspace where you can try different configurations (e.g., different training datasets or hyperparameters) of a KFP pipeline.\n",
    "\n",
    "Kubeflow Pipelines provides a Python SDK for building KFP components and pipelines. You will see a concrete example of using the SDK in the following sections. \n",
    "\n",
    "*More reading material: [Kubeflow Pipelines docs](https://www.kubeflow.org/docs/components/pipelines/v2/introduction/).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A demo pipeline\n",
    "This demo shows how to use Kubeflow Pipelines to define KFP components and chain them into a KFP pipeline that can complete multiple tasks, from data preparation to model deployment.\n",
    "\n",
    "In this example, we'll continue using the red wine quality dataset. At the end of this tutorial, we'll build a KFP pipeline that performs the following tasks:\n",
    "\n",
    "<img src=\"./images/kfp-demo.jpg\" />\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "from kfp.aws import use_aws_secret\n",
    "from kfp.v2.dsl import (\n",
    "    component,\n",
    "    Input,\n",
    "    Output,\n",
    "    Dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to kfp client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(host=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If **host** is left as **None**, it will use the cluster set in the current context of kubectl. The context of kubectl can be checked and configured using the following commands: \n",
    "```bash\n",
    "# Check current context, you should see \"kind-kind-ep\" as the output\n",
    "kubectl config current-context\n",
    "\n",
    "# If the output is not \"kind-kind-ep\", set current context to \"kind-kind-ep\"\n",
    "kubectl config use-context kind-kind-ep\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build KFP Components\n",
    "There are two ways to define components in KFP: [defining the components through Python functions](https://www.kubeflow.org/docs/components/pipelines/v1/sdk/python-function-components/) and [directly defining the component specification](https://www.kubeflow.org/docs/components/pipelines/v1/sdk/component-development/#creating-a-component-specification). In this tutorial (and the assignments), we'll use the first approach as it's more intuitive but feel free to explore the second approach especially if you want to use different languages other than Python.\n",
    "\n",
    "A KFP component can accept inputs and create outputs. The outputs of a KFP component can be used as another KFP component's inputs. There will be a concrete example later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Component for downloading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.10\",\n",
    "    packages_to_install=[\"pandas~=1.5.3\"],\n",
    "    output_component_file=\"components/pull_data_component.yaml\"\n",
    ")\n",
    "def pull_data(url: str, data: Output[Dataset]):\n",
    "    \"\"\"\n",
    "    Download a dataset and save it to a file\n",
    "    Args:\n",
    "        url: Dataset URL\n",
    "        data: Output of type Dataset where the downloaded dataset is saved\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(url, sep=\";\")\n",
    "    df.to_csv(data.path, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a deeper look at the code above.  \n",
    "\n",
    "When building a component, it's a good practice to start by considering its inputs and outputs. There are two categories of inputs and outputs in Kubeflow Pipelines: [Parameters](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/parameters/) that pass small amount of data such as strings, numbers, and booleans, and [Artifacts](https://www.kubeflow.org/docs/components/pipelines/v2/data-types/artifacts/) that pass large amount of data using files, such as a dataset and a model. \n",
    "\n",
    "- The dataset we want to use is a CSV file hosted in a website. Instead of hardcoding the URL in the code, we pass the URL as an *input* to the component so that this component can be reused in case the data location changes. \n",
    "- As for the *output*, we want to pass the downloaded dataset to the next task, so we specify that the component output should be a *Dataset* type (`Output[Dataset]`). All artifacts are saved by Kubeflow Pipelines to a storage service, which is MinIO in our setup. (Notice that the MinIO service used by Kubeflow Pipelines is a different instance from the one used by MLflow. The one used by Kubeflow Pipelines is running under \"kubeflow\" namespace, while the one used by MLflow is running under \"mlflow\" namespace). The *path* property of the Dataset class refers to the location where this artifact will be saved. We save the dataset to that location by using `df.to_csv(data.path, index=None)`. \n",
    "- The Python function used to create a KFP component needs to be standalone, meaning the packages needed by the function need to be imported inside the function. For example, we import the Pandas package inside the `pull_data` function. \n",
    "\n",
    "The component inputs are always declared as parameters in the function definition. When an output is an Artifact, it's also declared as a function parameter.\n",
    "```python\n",
    "def pull_data(url: str, data: Output[Dataset])\n",
    "```\n",
    "\n",
    "The `@component` annotation is needed to specify that the `pull_data` function needs to be transformed into a KFP component. Under the hood, KFP creates a factory function, which then creates a pipeline task that executes the `pull_data` function. [Several parameters](https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/sdk/python/kfp/v2/components/component_decorator.py) can be specified for the `@component` annotation. In our code, we use `base_image` to specify the Docker image where the function is running. We use `packages_to_install` to specify the Python packages that need to be installed before running the function. Finally, we use `output_component_file` to create a file that contains the specification for the newly built component. After running the above code cell, you'll see a file named \"pull_data_component.yaml\" appear in the \"components\" directory. You'll see your code there as well as other configurations for creating the KFP component. This way you can reuse the component in another project without needing to write the function again. For example, if you need to use this component for downloading other data, you can load the component using the following code:\n",
    "```python\n",
    "pull_data_component = kfp.components.load_component_from_file(\"components/pull_data_component.yaml\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Component for splitting data into training and testing datasets**\n",
    "\n",
    "Again, we start by considering the inputs and outputs of the component. The input of this component will come from the output Artifact of the `pull_data()` function above, so we annotate the parameter with the `Input[Dataset]` type. We want to have two outputs: a training and a testing dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.10\",\n",
    "    packages_to_install=[\"pandas~=1.5.3\", \"scikit-learn~=1.3.2\"],\n",
    "    output_component_file=\"components/preprocess_component.yaml\"\n",
    ")\n",
    "def preprocess(\n",
    "    data: Input[Dataset],\n",
    "    train_set: Output[Dataset],\n",
    "    test_set: Output[Dataset],\n",
    "):\n",
    "    \"\"\"\n",
    "    Read a dataset from a file, split it into a training and test dataset, and save the training and test dataset\n",
    "    into separate files\n",
    "    Args:\n",
    "        data: Input of type Dataset which the dataset is read from\n",
    "        train_set: Output of type Dataset where the training dataset is saved\n",
    "        test_set: Output of type Dataset where the test dataset is saved  \n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    data = pd.read_csv(data.path)\n",
    "    \n",
    "    # Split the data into training and test sets. (0.75, 0.25) split\n",
    "    train, test = train_test_split(data, random_state=42)\n",
    "    \n",
    "    # Save the training and test datasets into separate files\n",
    "    train.to_csv(train_set.path, index=None)\n",
    "    test.to_csv(test_set.path, index=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Component for training a model**\n",
    "\n",
    "This component accepts multiple inputs. Most of which are easy to understand (as you can see from the documentation strings inside the function) except an input named \"model_artifact_path\" which may be a bit confusing. Let's use an example to explain what this input means. Recall that in our setup, the MLflow service uses an MinIO storage service as the artifact store. MinIO is an open-source S3-compatible storage service. \n",
    "\n",
    "When we register a model to the MLflow service, we actually upload a few artifacts to MinIO:\n",
    "\n",
    "<img src=\"./images/mlflow-artifacts.png\" width=\"800\" />\n",
    "\n",
    "<img src=\"./images/minio.png\" width=\"1000\" />\n",
    "\n",
    "The model's S3 URI (e.g., s3://mlflow/9/fd05ffb7b4f541278966f292dd7dabba/artifacts/wine-quality in the example) follows the following structure: \n",
    "- \"s3://\" indicates that this is an S3 URI;\n",
    "- \"mlflow\" is the name of the bucket used by the MLflow service. A bucket can be seen as a top-level directory;\n",
    "- \"/9/fd05f.../artifacts/wine-quality\" can be seen as a hierarchy structure of subdirectories: \"9\" is the MLflow Experiment ID, \"fd05f...\" is the MLflow Run ID, \"artifacts\" is a default name picked up by MLflow, and \"wine-quality\" indicates the lowest-level subdirectory where the artifacts are stored. This is the value passed to the \"model_artifact_path\" input. We say this \"model_artifact_path\" is relative to the MLflow Run creating the artifacts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.10\",\n",
    "    packages_to_install=[\"pandas~=1.5.3\", \"numpy\", \"scikit-learn~=1.3.2\", \"mlflow==2.3.2\", \"boto3~=1.28.85\"],\n",
    "    output_component_file=\"components/train_component.yaml\"\n",
    ")\n",
    "def train(\n",
    "    train_set: Input[Dataset],\n",
    "    test_set: Input[Dataset],\n",
    "    mlflow_experiment_name: str,\n",
    "    mlflow_tracking_uri: str,\n",
    "    mlflow_s3_endpoint_url: str,\n",
    "    model_artifact_path: str,\n",
    "    alpha: float,\n",
    "    l1_ratio: float,\n",
    "    target: str = \"quality\"\n",
    ") -> NamedTuple(\"Output\", [(\"storage_uri\", str), (\"run_id\", str),]):\n",
    "    \"\"\"\n",
    "    Train a model, save the training metadata and the resulted artifacts to MLflow\n",
    "    Args:\n",
    "        train_set: Input where the training dataset is saved\n",
    "        test_set: Input where the test dataset is saved\n",
    "        mlflow_experiment_name: Name of the MLflow experiment\n",
    "        mlflow_tracking_uri: URI of MLflow's tracking server\n",
    "        mlflow_s3_endpoint_url: URL of MLflow's artifact store (MinIO)\n",
    "        model_artifact_path: The path where the artifacts of the model are stored in MLflow's artifact store (MinIO). It's relative to the MLflow Run. \n",
    "        alpha, l1_ratio: Hyperparameters that need to be configured\n",
    "        target: Target column name\n",
    "    \n",
    "    Returns: \n",
    "        namedtuple(\"Output\", [\"storage_uri\", \"run_id\"]) where storage_uri is the S3 URI of the saved model artifact \n",
    "        in the Mlflow's artifact store (MinIO) and run_id the ID of the MLflow run that produces the model\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    import mlflow\n",
    "    import mlflow.sklearn\n",
    "    import os\n",
    "    import logging\n",
    "    from collections import namedtuple\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def eval_metrics(actual, pred):\n",
    "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "        mae = mean_absolute_error(actual, pred)\n",
    "        r2 = r2_score(actual, pred)\n",
    "        return rmse, mae, r2\n",
    "    \n",
    "    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = mlflow_s3_endpoint_url\n",
    "    \n",
    "    # Load data\n",
    "    train = pd.read_csv(train_set.path)\n",
    "    test = pd.read_csv(test_set.path)\n",
    "    \n",
    "    # The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "    train_x = train.drop([target], axis=1)\n",
    "    test_x = test.drop([target], axis=1)\n",
    "    train_y = train[[target]]\n",
    "    test_y = test[[target]]\n",
    "    \n",
    "    logger.info(f\"Using MLflow tracking URI: {mlflow_tracking_uri}\")\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "    \n",
    "    logger.info(f\"Using MLflow experiment: {mlflow_experiment_name}\")\n",
    "    mlflow.set_experiment(mlflow_experiment_name)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        run_id = run.info.run_id\n",
    "        logger.info(f\"Run ID: {run_id}\")\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "        \n",
    "        logger.info(\"Fitting model...\")\n",
    "        model.fit(train_x, train_y)\n",
    "        \n",
    "        logger.info(\"Predicting...\")\n",
    "        predicted_qualities = model.predict(test_x)\n",
    "        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "        logger.info(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "        logger.info(\"RMSE: %s\" % rmse)\n",
    "        logger.info(\"MAE: %s\" % mae)\n",
    "        logger.info(\"R2: %s\" % r2)\n",
    "        \n",
    "        logger.info(\"Logging parameters and metrics to MLflow\")\n",
    "        mlflow.log_param(\"alpha\", alpha)\n",
    "        mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        \n",
    "        logger.info(\"Logging trained model\")\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            artifact_path=model_artifact_path,\n",
    "            registered_model_name=\"ElasticnetWineModel\",\n",
    "            serialization_format=\"pickle\"\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Logging predictions artifact to MLflow\")\n",
    "        np.save(\"predictions\", predicted_qualities)\n",
    "        mlflow.log_artifact(\n",
    "            local_path=\"predictions.npy\",\n",
    "            artifact_path=\"predicted_qualities\"\n",
    "        )\n",
    "        \n",
    "        # Prepare output\n",
    "        output = namedtuple(\"Output\", [\"storage_uri\", \"run_id\"])\n",
    "\n",
    "        # use get_artifact_uri to get the absolute S3 URI (s3://mlflow/<mlflow-experiment-id>/<mlflow-run-id>/artifacts/<model_artifact_path>)\n",
    "        return output(mlflow.get_artifact_uri(artifact_path=model_artifact_path), run_id)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the *pull_data* and *preprocess* components whose outputs are Artifacts, the outputs of the *train* components are Parameters. In this case, the component output is not declared as function parameters but indicated via return annotations. \n",
    "\n",
    "Since the *train* component outputs include more than one Parameter (`storage_uri` and `run_id`), we need to use [namedtuple](https://docs.python.org/3/library/collections.html#collections.namedtuple) to return the outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Component for deploying a model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.10\",\n",
    "    packages_to_install=[\"kserve==0.10.1\"],\n",
    "    output_component_file=\"components/deploy_model_component.yaml\"\n",
    ")\n",
    "def deploy_model(model_name: str, storage_uri: str):\n",
    "    \"\"\"\n",
    "    Deploy the model as an inference service to KServe\n",
    "    Args:\n",
    "        model_name: the name of the deployed inference service\n",
    "        storage_uri: the S3 URI of the saved model in MLflow's artifact store (MinIO)\n",
    "    \"\"\"\n",
    "    from kubernetes import client\n",
    "    from kserve import KServeClient\n",
    "    from kserve import constants\n",
    "    from kserve import V1beta1InferenceService\n",
    "    from kserve import V1beta1InferenceServiceSpec\n",
    "    from kserve import V1beta1PredictorSpec\n",
    "    from kserve import V1beta1SKLearnSpec\n",
    "    import logging\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    model_uri = storage_uri\n",
    "    logger.info(f\"MODEL URI: {model_uri}\")\n",
    "    namespace = \"kserve-inference\"\n",
    "    kserve_version=\"v1beta1\"\n",
    "    api_version = constants.KSERVE_GROUP + '/' + kserve_version\n",
    "    \n",
    "    isvc = V1beta1InferenceService(\n",
    "        api_version=api_version,\n",
    "        kind=constants.KSERVE_KIND,\n",
    "        metadata=client.V1ObjectMeta(\n",
    "            name=model_name,\n",
    "            namespace=namespace,\n",
    "        ),\n",
    "        spec=V1beta1InferenceServiceSpec(\n",
    "            predictor=V1beta1PredictorSpec(\n",
    "                service_account_name='kserve-sa',\n",
    "                sklearn=V1beta1SKLearnSpec(\n",
    "                    storage_uri=model_uri\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    kserve = KServeClient()\n",
    "    try:\n",
    "        kserve.create(inferenceservice=isvc)\n",
    "    except RuntimeError:\n",
    "        kserve.patch(name=model_name, inferenceservice=isvc, namespace=namespace)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define a KFP pipeline\n",
    "\n",
    "To build a pipeline, we need to define a function with a sequence of steps and annotate the function using the `dsl.pipeline` decorator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"redwine-pipeline\",\n",
    "    description=\"An example pipeline that deploys a redwine model\"\n",
    ")\n",
    "def pipeline(\n",
    "    url: str,\n",
    "    target: str,\n",
    "    mlflow_experiment_name: str,\n",
    "    mlflow_tracking_uri: str,\n",
    "    mlflow_s3_endpoint_url: str,\n",
    "    model_name: str,\n",
    "    alpha: float,\n",
    "    l1_ratio: float\n",
    "):\n",
    "    \"\"\"\n",
    "    Define a pipeline\n",
    "    Args:\n",
    "        url: URL for downloading the dataset\n",
    "        target: Target column name of the dataset\n",
    "        mlflow_experiment_name: Name of the MLflow experiment\n",
    "        mlflow_tracking_uri: URI of MLflow's tracking server\n",
    "        mlflow_s3_endpoint_url: URL of MLflow's artifact store (MinIO)\n",
    "        model_name: The name of the KServe inference service. It's also used as the model's artifact path relative to the MLflow Run\n",
    "        alpha, l1_ratio: Hyperparameters that need to be configured\n",
    "    \"\"\"\n",
    "\n",
    "    # When we call a component in a pipeline definition, it constructs a pipeline task (instantiated component)\n",
    "    pull_task = pull_data(url)\n",
    "    \n",
    "    # The preprocess task uses the output Artifact of the pull_data task as the input\n",
    "    preprocess_task = preprocess(data=pull_task.outputs[\"data\"])\n",
    "    \n",
    "    train_task = train(\n",
    "        train_set=preprocess_task.outputs[\"train_set\"],\n",
    "        test_set=preprocess_task.outputs[\"test_set\"],\n",
    "        target=target,\n",
    "        mlflow_experiment_name=mlflow_experiment_name,\n",
    "        mlflow_tracking_uri=mlflow_tracking_uri,\n",
    "        mlflow_s3_endpoint_url=mlflow_s3_endpoint_url,\n",
    "        model_artifact_path=model_name,\n",
    "        alpha=alpha,\n",
    "        l1_ratio=l1_ratio\n",
    "    )\n",
    "    \n",
    "    # The train task uploads the trained model to the MLflow service\n",
    "    # so it needs to access the required credentials of the MinIO storage service that MLflow uses.\n",
    "    # These credentials (username and password) have been deployed as a secret object named \"aws-secret\" to the \n",
    "    # Kubernetes cluster during the setup.\n",
    "    train_task.apply(use_aws_secret(secret_name=\"aws-secret\"))\n",
    "    \n",
    "    deploy_model(\n",
    "        model_name = model_name,\n",
    "        storage_uri=train_task.outputs[\"storage_uri\"]\n",
    "    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data pre-process task uses the output Artifact of the pull_data task as the input. To get an output Artifact of a previous task, we need to use the `outputs` dictionary and use the parameter name as the key.\n",
    "```python\n",
    "preprocess_task = preprocess(data=pull_task.outputs[\"data\"])\n",
    "``` \n",
    "The parameter \"data\" is defined in the `pull_data` function definition:\n",
    "```python\n",
    "def pull_data(url: str, data: Output[Dataset]):\n",
    "```\n",
    "\n",
    "Similarly, for the model deployment task, we get an output Parameter from another task.\n",
    "```python\n",
    "deploy_model_task = deploy_model(\n",
    "        ...\n",
    "        storage_uri=train_task.outputs[\"storage_uri\"]\n",
    "    )\n",
    "```\n",
    "The parameter name \"storage_uri\" is defined via the return annotation in the `train` function.\n",
    "```python\n",
    "def train(...):\n",
    "    ...\n",
    "    output = namedtuple(\"Output\", [\"storage_uri\", \"run_id\"])\n",
    "    return output(mlflow.get_artifact_uri(artifact_path=model_name), run_id)\n",
    "```\n",
    "\n",
    "If a component has a single Parameter output, e.g., \n",
    "```python\n",
    "@component()\n",
    "def plus(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "def plus_task = plus(1, 2)\n",
    "```\n",
    "its output can be accessed by `plus_task.output`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then specify arguments for the `pipeline` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify pipeline argument values\n",
    "arguments = {\n",
    "    \"url\": \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "    \"target\": \"quality\",\n",
    "    \"mlflow_tracking_uri\": \"http://mlflow.mlflow.svc.cluster.local:5000\", # this is how a service can be accessed inside the platform. The URL is in the format\n",
    "                                                                          # of http://<service-object-name>.<namespace>.svc.cluster.local:<service-port>\n",
    "    \"mlflow_s3_endpoint_url\": \"http://mlflow-minio-service.mlflow.svc.cluster.local:9000\",\n",
    "    \"mlflow_experiment_name\": \"demo-notebook\",\n",
    "    \"model_name\": \"wine-quality\",\n",
    "    \"alpha\": 0.5,\n",
    "    \"l1_ratio\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Submit a KFP run\n",
    "After we've defined the pipeline function, we can execute it using the `create_run_from_pipeline_func` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/527ef893-dd11-436c-9b3e-82dd2fbbff44\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/5cd93fd6-17d9-4039-bf93-9aa5215ccd6e\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=5cd93fd6-17d9-4039-bf93-9aa5215ccd6e)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name = \"demo-run\"\n",
    "experiment_name = \"demo-experiment\"\n",
    "\n",
    "client.create_run_from_pipeline_func(\n",
    "    pipeline_func=pipeline,\n",
    "    run_name=run_name,\n",
    "    experiment_name=experiment_name,\n",
    "    arguments=arguments, # These are the arguments passed to the pipeline function\n",
    "    mode=kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE, # KFP SDK has two versions (v1 and v2). We use v2 here\n",
    "    enable_caching=False # Disable caching for this pipeline, more details at https://www.kubeflow.org/docs/components/pipelines/v1/overview/caching-v2/\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see two links in the output but they don't work here. You can simply ignore them. \n",
    "\n",
    "We can now go to the Kubeflow Pipeline UI at [http://ml-pipeline-ui.local](http://ml-pipeline-ui.local) and navigate to the \"Experiments\" field. For example, we can see a KFP experiment called \"demo-experiment\" has been created, and there is a KFP run called \"demo-run\" under the \"demo-experiment\" KFP experiment.\n",
    "\n",
    "<img src=\"./images/kfp-experiment-overview.png\" width=900/>\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./images/kfp-run-overview.png\" width=900/>\n",
    "\n",
    "\n",
    "We can follow the progress of the \"demo-run\" KFP run by clicking the run name:\n",
    "\n",
    "<img src=\"./images/kfp-run-progress.png\" width=900/>\n",
    "<img src=\"./images/kfp-run-finish.png\" width=900/>\n",
    "\n",
    "We can also check the logging hyperparameters and metrics, as well as the registered model from MLflow at [http://mlflow-server.local](http://mlflow-server.local):\n",
    "\n",
    "<img src=\"./images/demo-mlflow-logging.png\" width=1200/>\n",
    "<img src=\"./images/demo-mlflow-model.png\" width=1200/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing the deployed inference service\n",
    "\n",
    "When the KFP run is completed, let's check if the inference service is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME           URL                                                READY   PREV   LATEST   PREVROLLEDOUTREVISION   LATESTREADYREVISION                    AGE\n",
      "wine-quality   http://wine-quality.kserve-inference.example.com   True           100                              wine-quality-predictor-default-00001   55s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get isvc wine-quality -n kserve-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example output:\n",
    "\n",
    "```\n",
    "NAME           URL                                                READY   PREV   LATEST   PREVROLLEDOUTREVISION   LATESTREADYREVISION                    AGE\n",
    "wine-quality   http://wine-quality.kserve-inference.example.com   True           100                              wine-quality-predictor-default-00001   2m7s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the inference service is ready, we can send some requests to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [5.655508704978511, 5.5175364387082615]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "input_sample = [\n",
    "        [7.8, 0.58, 0.02, 2, 0.073, 9, 18, 0.9968, 3.36, 0.57, 9.5],\n",
    "        [8.9, 0.22, 0.48, 1.8, 0.077, 29, 60, 0.9968, 3.39, 0.53, 9.4]\n",
    "    ]\n",
    "model_artifact_path = arguments[\"model_name\"]\n",
    "req_data = {\n",
    "    \"instances\": input_sample\n",
    "}\n",
    "headers = {}\n",
    "headers[\"Host\"] = f\"{model_artifact_path}.kserve-inference.example.com\"\n",
    "url = f\"http://kserve-gateway.local:30200/v1/models/{model_artifact_path}:predict\"\n",
    "result = requests.post(url, json=req_data, headers=headers)\n",
    "print(result.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example output: \n",
    "```text\n",
    "{'predictions': [5.655508704978511, 5.5175364387082615]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up by deleting the \"wine-quality\" inference service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceservice.serving.kserve.io \"wine-quality\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl -n kserve-inference delete isvc wine-quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For deleting KFP Experiments and Runs, please check [this notebook](./delete_from_kfp.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
