{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evidently\n",
    "\n",
    "Evidently is an open-source Python library for evaluating, testing, and monitoring data and ML models. To understand how to use Evidently, please first go through the [core concepts](https://docs.evidentlyai.com/readme/core-concepts) of Evidently. \n",
    "\n",
    "This tutorial provides examples of Evidently Report, TestSuite, and Monitoring UI, using the familiar dataset of bike sharing demand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: kserve 0.10.1\n",
      "Uninstalling kserve-0.10.1:\n",
      "  Successfully uninstalled kserve-0.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/yumoL/evidently.git\n",
      "  Cloning https://github.com/yumoL/evidently.git to /tmp/pip-req-build-hlvan4ew\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/yumoL/evidently.git /tmp/pip-req-build-hlvan4ew\n",
      "  Resolved https://github.com/yumoL/evidently.git to commit 2fb9dbe2cdfc619498d1804b7e52e9c95dd8d0e2\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: plotly>=5.5.0 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from evidently==0.4.9) (5.15.0)\n",
      "Requirement already satisfied: statsmodels>=0.12.2 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from evidently==0.4.9) (0.14.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24.0 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from evidently==0.4.9) (1.3.2)\n",
      "Requirement already satisfied: pandas>=1.3.5 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from evidently==0.4.9) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from evidently==0.4.9) (1.26.0)\n",
      "Collecting nltk>=3.6.7 (from evidently==0.4.9)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.5.4 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from evidently==0.4.9) (1.10.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from evidently==0.4.9) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /home/user/.local/lib/python3.10/site-packages (from evidently==0.4.9) (6.0)\n",
      "Requirement already satisfied: pydantic<2 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from evidently==0.4.9) (1.10.13)\n",
      "Collecting fastapi>=0.100.0 (from evidently==0.4.9)\n",
      "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fastapi-restful>=0.5.0 (from evidently==0.4.9)\n",
      "  Downloading fastapi_restful-0.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting typing-inspect>=0.9.0 (from evidently==0.4.9)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting uvicorn>=0.22.0 (from evidently==0.4.9)\n",
      "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m974.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting watchdog>=3 (from evidently==0.4.9)\n",
      "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typer>=0.3 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from evidently==0.4.9) (0.9.0)\n",
      "Collecting rich>=13 (from evidently==0.4.9)\n",
      "  Downloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting iterative-telemetry>=0.0.5 (from evidently==0.4.9)\n",
      "  Downloading iterative_telemetry-0.0.8-py3-none-any.whl (10 kB)\n",
      "Collecting pyarrow<11.0dev (from evidently==0.4.9)\n",
      "  Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from fastapi>=0.100.0->evidently==0.4.9) (3.7.1)\n",
      "Collecting starlette<0.28.0,>=0.27.0 (from fastapi>=0.100.0->evidently==0.4.9)\n",
      "  Using cached starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from fastapi>=0.100.0->evidently==0.4.9) (4.8.0)\n",
      "Requirement already satisfied: psutil<6,>=5 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from fastapi-restful>=0.5.0->evidently==0.4.9) (5.9.0)\n",
      "Requirement already satisfied: appdirs in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from iterative-telemetry>=0.0.5->evidently==0.4.9) (1.4.4)\n",
      "Requirement already satisfied: filelock in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from iterative-telemetry>=0.0.5->evidently==0.4.9) (3.12.4)\n",
      "Collecting distro (from iterative-telemetry>=0.0.5->evidently==0.4.9)\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: click in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from nltk>=3.6.7->evidently==0.4.9) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from nltk>=3.6.7->evidently==0.4.9) (1.2.0)\n",
      "Collecting regex>=2021.8.3 (from nltk>=3.6.7->evidently==0.4.9)\n",
      "  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from nltk>=3.6.7->evidently==0.4.9) (4.66.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from pandas>=1.3.5->evidently==0.4.9) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from pandas>=1.3.5->evidently==0.4.9) (2023.3.post1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from plotly>=5.5.0->evidently==0.4.9) (8.2.3)\n",
      "Requirement already satisfied: packaging in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from plotly>=5.5.0->evidently==0.4.9) (23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from requests>=2.21.0->evidently==0.4.9) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from requests>=2.21.0->evidently==0.4.9) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from requests>=2.21.0->evidently==0.4.9) (1.26.17)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from requests>=2.21.0->evidently==0.4.9) (2023.7.22)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13->evidently==0.4.9)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from rich>=13->evidently==0.4.9) (2.15.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from scikit-learn>=0.24.0->evidently==0.4.9) (3.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from statsmodels>=0.12.2->evidently==0.4.9) (0.5.3)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.9.0->evidently==0.4.9)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: h11>=0.8 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from uvicorn>=0.22.0->evidently==0.4.9) (0.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.100.0->evidently==0.4.9) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.100.0->evidently==0.4.9) (1.1.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13->evidently==0.4.9)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: six in /home/user/anaconda3/envs/mlops_eng/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels>=0.12.2->evidently==0.4.9) (1.16.0)\n",
      "Building wheels for collected packages: evidently\n",
      "  Building wheel for evidently (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for evidently: filename=evidently-0.4.9-py3-none-any.whl size=3303512 sha256=a0d91a589b5cefd9613782c7e3c4b798bfccf51baa65905cd7855d50d1844ede\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9ubz66wn/wheels/be/ea/a4/016962817d32231a0b78093014d32a799806196f1cf85405f8\n",
      "Successfully built evidently\n",
      "Installing collected packages: watchdog, uvicorn, regex, pyarrow, mypy-extensions, mdurl, distro, typing-inspect, starlette, nltk, markdown-it-py, iterative-telemetry, rich, fastapi, fastapi-restful, evidently\n",
      "  Attempting uninstall: uvicorn\n",
      "    Found existing installation: uvicorn 0.16.0\n",
      "    Uninstalling uvicorn-0.16.0:\n",
      "      Successfully uninstalled uvicorn-0.16.0\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 11.0.0\n",
      "    Uninstalling pyarrow-11.0.0:\n",
      "      Successfully uninstalled pyarrow-11.0.0\n",
      "  Attempting uninstall: starlette\n",
      "    Found existing installation: starlette 0.22.0\n",
      "    Uninstalling starlette-0.22.0:\n",
      "      Successfully uninstalled starlette-0.22.0\n",
      "  Attempting uninstall: fastapi\n",
      "    Found existing installation: fastapi 0.88.0\n",
      "    Uninstalling fastapi-0.88.0:\n",
      "      Successfully uninstalled fastapi-0.88.0\n",
      "Successfully installed distro-1.8.0 evidently-0.4.9 fastapi-0.104.1 fastapi-restful-0.5.0 iterative-telemetry-0.0.8 markdown-it-py-3.0.0 mdurl-0.1.2 mypy-extensions-1.0.0 nltk-3.8.1 pyarrow-10.0.1 regex-2023.10.3 rich-13.7.0 starlette-0.27.0 typing-inspect-0.9.0 uvicorn-0.24.0.post1 watchdog-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Uninstall kserve as it causes version conflicts with Evidently and we don't need it anymore\n",
    "%pip uninstall kserve -y \n",
    "\n",
    "# The latest release of Evidently (at the time when coding the assignment set) has some issues with the Monitoring UI. The fixes have been pushed to its Github repository, \n",
    "# so we directly install the package from Github.\n",
    "# The repository used in this assignment is forked from the Evidently repository for immutability as the original repository is updated continuously.\n",
    "%pip install git+https://github.com/yumoL/evidently.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "import webbrowser\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Tuple\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from evidently import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset, RegressionPreset\n",
    "from evidently.test_suite import TestSuite\n",
    "from evidently.tests import TestValueR2Score\n",
    "from evidently.ui.dashboards import ReportFilter, DashboardPanelTestSuiteCounter, CounterAgg, DashboardPanelPlot, PanelValue, PlotType, DashboardConfig\n",
    "from evidently.renderers.html_widgets import WidgetSize\n",
    "from evidently import metrics\n",
    "from evidently.ui.workspace import Workspace, Project\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "WORKING_DIR = Path.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first download the dataset and do some pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "dataset_url = \"https://raw.githubusercontent.com/yumoL/mlops_eng_course_datasets/master/intro/bike-demanding/train_full.csv\"\n",
    "input_df = pd.read_csv(dataset_url)\n",
    "\n",
    "# Preprocess\n",
    "input_df[\"datetime\"] = pd.to_datetime(input_df[\"datetime\"])\n",
    "\n",
    "# create hour, day and month variables from datetime column\n",
    "input_df[\"hour\"] = input_df[\"datetime\"].dt.hour\n",
    "input_df[\"day\"] = input_df[\"datetime\"].dt.day\n",
    "input_df[\"month\"] = input_df[\"datetime\"].dt.month\n",
    "\n",
    "# Set datetime as index\n",
    "input_df.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "# drop casual and registered columns, we only use the \"count\" column as the target\n",
    "input_df.drop([\"casual\", \"registered\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"count\"\n",
    "categorical_features=[\"season\", \"holiday\", \"workingday\"]\n",
    "\n",
    "def split_x_y(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Split features and targets from a given DataFrame\n",
    "    \"\"\"\n",
    "    return df.drop([target], axis=1), df[[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use data for January of 2011 as the training data to train a LightGBM regression model. (The dataset originates from Kaggle, where only data from the initial 19 days of each month is accessible. The remaining days are reserved for Kaggle's evaluation purposes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = input_df.loc['2011-01-01 00:00:00':'2011-01-19 23:00:00']\n",
    "train_x, train_y = split_x_y(train)\n",
    "\n",
    "model = LGBMRegressor(random_state=42)\n",
    "model.fit(train.drop([target], axis=1), train[[target]], categorical_feature=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the data for February of 2011 as the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 score for the testing data is 0.7758083893824562\n"
     ]
    }
   ],
   "source": [
    "test = input_df.loc['2011-02-01 00:00:00':'2011-02-19 23:00:00']\n",
    "test_x, test_y = split_x_y(test)\n",
    "predictions = model.predict(test_x)\n",
    "r2 = r2_score(y_true=test_y, y_pred=predictions)\n",
    "print(f\"The r2 score for the testing data is {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, we can start to prepare a reference dataset. This dataset serves as a baseline for detecting target and data drift, as well as the training-serving skew. To calculate data drift, the reference dataset should have the features. To calculate model performance metrics (e.g., MAE and R2 score), the reference should also have the targets (i.e., ground truth) and the predicted values.\n",
    "\n",
    "In this example, we use the testing data as the reference data. It's worth noting that the reference data doesn't have to be the testing data. Testing data can be used as the reference data but they are not the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = test.copy()\n",
    "# Add predicted values as a new column\n",
    "reference[\"prediction\"] = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, suppose our model needs to make prediction on the data for March of 2011. Similar to the reference dataset, we also need to construct a production dataset that have model inputs (features), outputs (predictions), and targets (ground truth). In reality, this involves collecting inputs and ground truth from different sources. In our example, the inputs and ground truth are already available in the downloaded data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = input_df.loc['2011-03-01 00:00:00':'2011-03-19 23:00:00']\n",
    "\n",
    "# curr_x is the inputs received by the model \n",
    "curr_x, _ = split_x_y(current)\n",
    "\n",
    "production = current.copy()\n",
    "production[\"prediction\"] = model.predict(curr_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently needs information of dataset columns. The information includes which columns serve as inputs, which column contains the predicted values, and which represents the ground truth. Additionally, Evidently also needs to know which input columns are numerical and which categorical so that it can select the correct methods for drift detection. \n",
    "This information can be passed as an argument to Evidently using a `ColumnMapping` object. \n",
    "\n",
    "More details of ColumnMapping can be found [here](https://docs.evidentlyai.com/user-guide/input-data/column-mapping). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=[\"season\", \"holiday\", \"workingday\"]\n",
    "numerical_features = list(filter(lambda feature: feature not in categorical_features, train_x.columns))\n",
    "column_mapping_conf = {\n",
    "    \"numerical_features\": numerical_features,\n",
    "    \"categorical_features\": categorical_features,\n",
    "    \"prediction\": \"prediction\",\n",
    "    \"target\": target\n",
    "}\n",
    "column_mapping = ColumnMapping(**column_mapping_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "Now, let's build an Evidently Report using the `RegressionPreset` and `DataDriftPreset` Metric Presets.  \n",
    "\n",
    "After running the next code cell, you'll see an Evidently Report saved to an HTML file (\"bike_report.html\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = Report(metrics=[RegressionPreset(), DataDriftPreset()])\n",
    "\n",
    "# reference_data is, literally, the reference that serves as a baseline. current_data is the data we want to monitor\n",
    "report.run(reference_data=reference, current_data=production, column_mapping=column_mapping)\n",
    "report.save_html(\"bike_report.html\")\n",
    "webbrowser.open(\"file:///\" + str(WORKING_DIR/\"bike_report.html\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Report is mostly self-explanatory. For more information, please refer to the Evidently docs of [RegressionPreset](https://docs.evidentlyai.com/presets/reg-performance) and [DataDriftPreset](https://docs.evidentlyai.com/presets/data-drift).\n",
    "\n",
    "### Some clarifications:\n",
    "\n",
    "In the \"Regression Model Performance\" part, you'll see a summary of model quality metrics as below. The values in parentheses represent the standard deviation of the error values. For instance, `32.89 (38.76)` indicates that the mean absolute error is 32.89, and the standard deviation of the absolute error values is 38.76.\n",
    "\n",
    "<img src=\"./images/performance-metric-summary.png\" width=700/>\n",
    "\n",
    "In the \"Predicted vs Actual\" part, you'll see two contour plots showing predicted versus actual values for the production and reference datasets. You may notice that these plots are scatter plots in the documentation. In a scatter plot, you can see all the individual data points. A contour plot aggregates the data points and presents them as contours. The idea is that if we have a large dataset and try to present it as a scatter plot, this would result in points overlapping and hiding patterns. With a contour plot, we can get the general shape of the distribution, and the plot is more lightweight. We can also visually see more \"dense\" areas where most of the original data points are (with darker color), and more \"sparse\" areas where there are only a few observations (with light line contour). \n",
    "\n",
    "<img src=\"./images/contour1.png\" width=1000/>\n",
    "\n",
    "If you want to see the scatter plots, you can add an option to the report as follows.\n",
    "\n",
    "```python\n",
    "my_report = Report(metrics=[RegressionPreset(),],\n",
    "    options={\"render\": {\"raw_data\": True}}\n",
    ")\n",
    "```\n",
    "This will result in scatter plots (showing all individual data points) as below. \n",
    "\n",
    "<img src=\"./images/scatterplot.png\" width=1000/>\n",
    "\n",
    "\n",
    "In the \"Predicted vs Actual in Time\" part as shown below,\n",
    "\n",
    "<img src=\"./images/predicted-actual-in-time.png\" width=1000 />\n",
    "\n",
    "the index of a DataFrame gets binned based on the date. The values in the bin are averaged. For each bin, it shows the mean (the lines), and +/-standard deviation (the lightly colored zones). The y-axis is the mean value.\n",
    "\n",
    "If there is no index specified in the DataFrames, Evidently will use the default index starting at 0 as shown below (The number on the x-axis is the number of the bin):\n",
    "\n",
    "<img src=\"./images/predicted-actual-in-time-no-index.png\" width=1000 />\n",
    "\n",
    "\n",
    "In the part of data drift, the `drift-score` is the p-value of the statistical test. \n",
    "\n",
    "<img src=\"./images/data-drift.png\" width=1000 />\n",
    "\n",
    "By default, evidently selects a statistical test based on the column type and data size. More about the data drift algorithms used by Evidently can be found [here](https://docs.evidentlyai.com/reference/data-drift-algorithm). In this example, K-S test, Z-test, and Chi-Square test are used, the default p-value threshold for these tests is 0.05. Evidently allows for customizing which statistical test should be applied to which column and the threshold. E.g., \n",
    "\n",
    "```python\n",
    "# Use Wasserstein distance to calculate drift for the \"windspeed\" column and set the threshold to 0.02\n",
    "from evidently.calculations.stattests import wasserstein_stat_test\n",
    "report = Report(metrics=[RegressionPreset(), DataDriftPreset(per_column_stattest={\"windspeed\": wasserstein_stat_test}, per_column_stattest_threshold={\"windspeed\": 0.02})])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TestSuite\n",
    "An Evidently TestSuite works similarly as the Report. In this example, we specify an individual test instead of using a pre-built Test Preset. Run the next code cell should also save the TestSuite to an HTML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The TestSuite has only one test. The test will fail if the r2 score of the predictions on the production data is not greater than 0.9\n",
    "test_suite = TestSuite(tests=[TestValueR2Score(gt=0.9)])\n",
    "test_suite.run(reference_data=reference, current_data=production, column_mapping=column_mapping)\n",
    "test_suite.save_html(\"bike_test.html\")\n",
    "webbrowser.open(\"file:///\" + str(WORKING_DIR/\"bike_test.html\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring UI\n",
    "Evidently provides a user interface (Monitoring UI) that helps you organize your Reports and TestSuites and visualize the metrics and test results in a dashboard. Let's first look at three additional concepts used by Evidently:\n",
    "- Snapshot: As per Evidently docs, \"a snapshot is a JSON version of the Evidently Report or Test Suite. After you generate the Report or Test Suite and save it as a snapshot, you can load it back and restore it as in the HTML or other formats\". Multiple snapshots need to be captured (e.g., periodically) so that we can see how some metrics/test results change over a period of time. \n",
    "- Workspace: A Workspace is a directory that stores snapshots. \n",
    "- Project: A Project is a sub-directory of a Workspace. It allows for organizing snapshots, for example, for individual models.\n",
    "- Monitoring Dashboard: Each Project can have a Dashboard that visualizes how some metrics/test results change over a period of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create an Evidently Workspace and initialize a Project to that Workspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_evidently_project(workspace: Workspace, project_name: str) -> Project:\n",
    "    \"\"\"\n",
    "    Create a Project to a Workspace\n",
    "    Args:\n",
    "        workspace: An Evidently Workspace\n",
    "        project_name: Name of the Project\n",
    "    \"\"\"\n",
    "    # Delete any projects whose name is the given project_name to avoid duplicated projects\n",
    "    for project in workspace.search_project(project_name=project_name):\n",
    "        workspace.delete_project(project_id=project.id)\n",
    "\n",
    "    # Create a project at Evidently\n",
    "    project = workspace.create_project(name=project_name)\n",
    "\n",
    "    # Create a dashboard\n",
    "    project.dashboard = DashboardConfig(name=project_name, panels=[])\n",
    "\n",
    "    project.dashboard.add_panel(\n",
    "        DashboardPanelTestSuiteCounter(\n",
    "            title=\"R2 Score\",\n",
    "            agg=CounterAgg.LAST\n",
    "        ),\n",
    "    )\n",
    "    project.dashboard.add_panel(\n",
    "         DashboardPanelPlot(\n",
    "                title=\"R2 Score\",\n",
    "                filter=ReportFilter(metadata_values={}, tag_values=[]),\n",
    "                values=[\n",
    "                    PanelValue(\n",
    "                        metric_id=\"RegressionQualityMetric\",\n",
    "                        field_path=metrics.RegressionQualityMetric.fields.current.r2_score,\n",
    "                        legend=\"R2\",\n",
    "                    ),\n",
    "                ],\n",
    "                plot_type=PlotType.LINE,\n",
    "                size=WidgetSize.FULL,\n",
    "            )\n",
    "    )\n",
    "\n",
    "    project.save()\n",
    "    return project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Workspace\n",
    "workspace = Workspace.create(WORKING_DIR/\"my_workspace\")\n",
    "\n",
    "# Init a Project\n",
    "project = init_evidently_project(workspace=workspace, project_name=\"bike_project\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next code cell, we'll generate Reports and TestSuites for March, April, May and June of 2011 and upload the Reports and TestSuites as snapshots to the Evidently Project we just created. We'll also add a tag and timestamp to the Reports and TestSuites:\n",
    "```python\n",
    "report = Report(metrics=[...], tags=..., timestamp=...)\n",
    "```\n",
    "Tags can be used to provide some additional information for the Reports/TestSuites, such as the model version being monitored. If no timestamp is specified, Evidently will use the computation time of the Report/TestSuite as the timestamp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_periods = [('2011-03-01 00:00:00', '2011-03-19 23:00:00'), ('2011-04-01 00:00:00', '2011-04-19 23:00:00'),  \n",
    "                ('2011-05-01 00:00:00', '2011-05-19 23:00:00'), ('2011-06-01 00:00:00', '2011-06-19 23:00:00')]\n",
    "\n",
    "for i in range(len(time_periods)):\n",
    "    period = time_periods[i]\n",
    "    production = input_df[period[0]:period[1]]\n",
    "    prod_x, _ = split_x_y(production)\n",
    "    production[\"prediction\"] = model.predict(prod_x)\n",
    "\n",
    "    # Suppose the Report/TestSuite is generated one hour later when a period ends\n",
    "    timestamp = datetime.strptime(\n",
    "        period[1], \"%Y-%m-%d %H:%M:%S\") + timedelta(hours=1)\n",
    "\n",
    "    # Suppose we retrain a new model version for every period\n",
    "    tags = [f\"bike-model-v{i+1}\"]\n",
    "\n",
    "    report = Report(metrics=[RegressionPreset(),\n",
    "                    DataDriftPreset()], tags=tags, timestamp=timestamp)\n",
    "    report.run(reference_data=reference, current_data=production,\n",
    "               column_mapping=column_mapping)\n",
    "    # Upload Report snapshot\n",
    "    workspace.add_report(project_id=project.id, report=report)\n",
    "\n",
    "    test_suite = TestSuite(tests=[TestValueR2Score(\n",
    "        gt=0.6)], tags=tags, timestamp=timestamp)\n",
    "    test_suite.run(reference_data=reference,\n",
    "                   current_data=production, column_mapping=column_mapping)\n",
    "    # Upload TestSuite snapshot\n",
    "    workspace.add_test_suite(project_id=project.id, test_suite=test_suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the Evidently Monitoring UI service using the following command:\n",
    "```bash\n",
    "# switch to mlops_eng in your terminal\n",
    "# under the same directory as this notebook\n",
    "evidently ui --workspace ./my_workspace\n",
    "```\n",
    "\n",
    "Go to [http://localhost:8000](http://localhost:8000), you'll see there is one Evidently Project (\"bike_project\") listed in the Workspace:\n",
    "\n",
    "<img src=\"./images/bike_project.png\" width=1000/>\n",
    "\n",
    "Click the project, you'll see a Monitoring Dashboard with two panels. The upper panel shows that the latest test of R2 score failed. The lower panel shows the changes of R2 score over the past four months. The data shown in the panels is captured from the four TestSuite snapshots we just generated. \n",
    "\n",
    "<img src=\"./images/dashboard.png\" width=1000/>\n",
    "\n",
    "If you go to the \"REPORTS\" and \"TEST SUITES\" fields, you'll four Reports and four TestSuites, respectively, one for each month and each model version. \n",
    "\n",
    "<img src=\"./images/reports.png\" width=1000/>\n",
    "<img src=\"./images/test-suites.png\" width=1000/>\n",
    "\n",
    "If you open one of the Reports/Test Suites, you'll see a similar page as the previous \"bike_report.html\"/\"bike_test.html\" file.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
